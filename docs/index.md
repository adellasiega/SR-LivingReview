---
hide:
  - navigation
---


# **A Living Review of Symbolic Regression**

Symbolic regression (SR) is a rapidly growing subfield of machine learning aiming to learn the analytical form of models that underlie data by searching the space of mathematical expressions. A growing interest in SR is taking place in AI community because it promotes interpretability, i.e., it learns a transparent relationship between the input and the output. 

This document provides a list of state-of-the-art methods, datasets, and applications of symbolic regression as part of the recent review entitled ***Interpretable Scientific Discovery with Symbolic Regression: A Review***. The goal is to list all research works on symbolic regression, so *this list will continue to evolve*. This living review was proposed in the mentioned review in analogy with HEP ML Living Review ([link](https://iml-wg.github.io/HEPML-LivingReview/)).

<!-- [<img src="https://s18955.pcdn.co/wp-content/uploads/2018/02/github.png" width="25"/>](https://github.com/user/repository/subscription) -->

<!-- This living review was proposed in the mentioned review in analogy with [HEP ML Living Review](https://iml-wg.github.io/HEPML-LivingReview/). The goal is to list all research works on symbolic regression, so it is expected that ***this list will continue to evolve***. The fact that a paper is listed in this document does not endorse or validate its content - that is for the community (and for peer review) to decide. -->

[![download](https://img.shields.io/badge/download-review-blue.svg)](https://arxiv.org/pdf/2211.10873.pdf)

??? note "SR Methods"
    <div class="meta_for_parser tablespecs"
    style="font-size: 1pt;visibility:hidden" markdown>
    ##  SR Methods
    </div>

    ### Regression-based
        
    ??? note "Linear approach"
          
          * [Discovering governing equations from data by sparse identification of nonlinear dynamical systems](https://www.pnas.org/content/pnas/113/15/3932.full.pdf?with-ds=yes&source=post_page---------------------------)[[DOI]](https://www.pnas.org/doi/full/10.1073/pnas.1517384113) (SINDY)
          * [Data-driven discovery of coordinates and governing equations](https://www.pnas.org/content/pnas/116/45/22445.full.pdf) [[DOI]](https://www.pnas.org/doi/10.1073/pnas.1906995116) [![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)`code`](https://github.com/kpchamp/SindyAutoencoders) (SINDY + AE)
          
    ??? note "Non-linear approaches"
      
          * [AI Feynman: a Physics-Inspired Method for Symbolic Regression](https://arxiv.org/pdf/1905.11481.pdf) [[DOI]](https://www.science.org/doi/10.1126/sciadv.aay2631) [![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)`code`](https://github.com/SJ001/AI-Feynman)
          * [Integration of Neural Network-Based Symbolic Regression in Deep Learning for Scientific Discovery](https://arxiv.org/pdf/1912.04825.pdf)
          * [Symbolic regression for scientific discovery: an application to wind speed forecasting](https://arxiv.org/pdf/2102.10570.pdf)
          * [Relational inductive biases, deep learning, and graph networks](https://arxiv.org/pdf/1806.01261.pdf)
          * [Extrapolation and learning equations](https://arxiv.org/pdf/1610.02995.pdf) (EQL)
          * [Learning Equations for Extrapolation and Control](http://proceedings.mlr.press/v80/sahoo18a/sahoo18a.pdf)(EQL_division)

    ### Expression tree-based
    
    ??? note "Genetic programming (GP)"
        
         * [Eurequa](https://link.springer.com/content/pdf/10.1007/s10710-010-9124-z.pdf)
         * [PySR: High-Performance Symbolic Regression in Python and Julia](https://github.com/MilesCranmer/pysr)
         * Genetic programming as a means for programming computers by natural selection [[DOI]](https://link.springer.com/article/10.1007/BF00175355)
         * Order of Nonlinearity as a Complexity Measure for Models Generated by Symbolic Regression via Pareto Genetic Programming [[DOI]](https://ieeexplore.ieee.org/document/4632147)
         * Improving Symbolic Regression with Interval Arithmetic and Linear Scaling [[DOI]](https://link.springer.com/chapter/10.1007/3-540-36599-0_7)
         * Accuracy in Symbolic Regression [[DOI]](https://link.springer.com/chapter/10.1007/978-1-4614-1770-5_8)
         * Semantically-based crossover in genetic programming: application to real-valued symbolic regression [[DOI]](https://link.springer.com/article/10.1007/s10710-010-9121-2)

    ??? note "Reinforcement learning (RL)"
        <div class="meta_for_parser tablespecs"
        style="font-size: 1pt;visibility:hidden" markdown>
        ####  Reinforcement learning
        </div>
        
          * [Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients](https://arxiv.org/abs/1912.04871) [[DOI]](https://openreview.net/forum?id=m5Qsh0kBQG) [![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)`code`](https://github.com/brendenpetersen/deep-symbolic-optimization)
          * [Symbolic Regression via Neural-Guided Genetic Programming Population Seeding](https://arxiv.org/abs/2111.00053) [[DOI]](https://proceedings.neurips.cc/paper/2021/hash/d073bb8d0c47f317dd39de9c9f004e9d-Abstract.html)[![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)`code`](https://github.com/brendenpetersen/deep-symbolic-optimization)
          * [Physical Symbolic Optimization](https://arxiv.org/pdf/2303.03192.pdf) [![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)`code`](https://github.com/WassimTenachi/PhySO/tree/main)

    ??? note "Transformer neural network (TNN)"
    
          * [End-to-end symbolic regression with transformers](https://arxiv.org/abs/2204.10532) [![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)`code`](https://github.com/facebookresearch/symbolicregression)
          * [Neural Symbolic Regression that Scales](https://arxiv.org/abs/2106.06427) [![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)`code`](https://github.com/SymposiumOrganization/NeuralSymbolicRegressionThatScales)
          * [SymbolicGPT: A Generative Transformer Model for Symbolic Regression](https://arxiv.org/pdf/2106.14131.pdf) [![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)`code`](https://github.com/mojivalipour/symbolicgpt)
          * [SYMBA: SYMBOLIC COMPUTATION OF SQUARED AMPLITUDES IN HIGH ENERGY PHYSICS WITH MACHINE LEARNING](https://arxiv.org/pdf/2206.08901.pdf) [![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)`code`](https://github.com/ML4SCI/SYMBAHEP)
      
    ### Other SR approaches
    
    ??? note "Physics-inspired"
        <div class="meta_for_parser tablespecs"
        style="font-size: 1pt;visibility:hidden" markdown>
        ####  Physics-inspired
        </div>
        
        * [AI Feynman: a Physics-Inspired Method for Symbolic Regression](https://arxiv.org/pdf/1905.11481.pdf) [[DOI]](https://www.science.org/doi/10.1126/sciadv.aay2631) [![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)`code`](https://github.com/SJ001/AI-Feynman)
      
    ??? note "Mathematics-inspired"
        <div class="meta_for_parser tablespecs"
        style="font-size: 1pt;visibility:hidden" markdown>
        ####  Mathematics-inspired
        </div>
        
        * [Demystifying Black-box Models with Symbolic Metamodels](https://www.vanderschaar-lab.com/papers/NIPS2019_DBM.pdf) [[DOI]](https://papers.nips.cc/paper_files/paper/2019/hash/567b8f5f423af15818a068235807edc0-Abstract.html) [![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)`code`](https://github.com/vanderschaarlab/mlforhealthlabpub/tree/main/alg/symbolic_metamodeling)
      
    ??? note "Computational approach"
        <div class="meta_for_parser tablespecs"
        style="font-size: 1pt;visibility:hidden" markdown>
        ####  Computational approach
        </div>    
    
        * [Distilling Free-Form Natural Laws from Experimental Data](https://www.science.org/doi/10.1126/science.1165893)

??? note "SR Datasets"
    <div class="meta_for_parser tablespecs"
    style="font-size: 1pt;visibility:hidden" markdown>
    ##  SR Datasets
    </div>
    
    Data sets ($\mathcal{D}$) are categorized into two main groups:
    
    **Synthetic data**  for which the analytical form of the underlying model is known and used to generate data points. <br>
    Example: $f(x) = 2x^2 + \cos(x) \rightarrow \mathcal{D}=(x_i,f(x_i))_{i=1}^{n}$ for $x \in [0,1]$

     **Real-world data** for which the underlying model is unknown.<br>
     
      <table>
          <thead>
              <tr>
                  <th>Type</th>
                  <th>Category</th>
                  <th>Underlying model</th>
                  <th>Benchmarks</th>
                  <th>Number of equations</th>
              </tr>
          </thead>
          <tbody>
              <tr>
                  <td rowspan=10>Synthetic data</td>
                  <td rowspan=2>Physics</td>
                  <td>Physics equations</td>
                  <td>AIFeynman</td>
                  <td>120</td>
              </tr>
              <tr>
                  <td>Ordinary differential equations</td>
                  <td>Strogatz</td>
                  <td>10</td>
              </tr>
              <tr>
                  <td rowspan=8>Mathematics</td>
                  <td rowspan=8>monomials, polynomials, <br> trigonometric, exponential, <br> logarithm, power law, etc.</td> 
                  <td>Koza</td><td>3</td>
              </tr>
              <tr><td>Keijer</td><td>15</td></tr>
              <tr><td>Vladislavleva</td><td>8</td></tr>
              <tr><td>Nguyen</td><td>12</td></tr>
              <tr><td>Korns</td><td>15</td></tr>
              <tr><td>R</td><td>3</td></tr>
              <tr><td>Jin</td><td>6</td></tr>
              <tr><td>Livermore</td><td>22</td></tr>  
              <tr>
                  <td rowspan=1>Real world data</td>
                  <td>economy, climate, commerce, etc.</td>
                  <td>NA</td>
                  <td>Penn Machine Learning Benchmarks</td>
                  <td>419</td>
              </tr>
          </tbody>
      </table>

??? note "Benchmarks"
    <div class="meta_for_parser tablespecs"
    style="font-size: 1pt;visibility:hidden" markdown>
    ##  Benchmarks
    </div>
    
      * [Contemporary Symbolic Regression Methods and their Relative Performance](https://arxiv.org/pdf/2107.14351.pdf) [![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)`code`](https://github.com/cavalab/srbench)
      
??? note "Reviews"
    <div class="meta_for_parser tablespecs"
    style="font-size: 1pt;visibility:hidden" markdown>
    ##  Reviews
    </div>
    
      * [Interpretable Scientific Discovery with Symbolic Regression: A Review](https://arxiv.org/pdf/2211.10873.pdf)

??? "SR Applications in physics"
    <div class="meta_for_parser tablespecs"
    style="font-size: 1pt;visibility:hidden" markdown>
    ##  SR Applications
    </div>

      * [Discovering Symbolic Models from Deep Learning with Inductive Biases](https://arxiv.org/pdf/2006.11287.pdf) [![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)`code`](https://github.com/MilesCranmer/symbolic_deep_learning) (GNN + SR)
      * [Data-driven discovery of coordinates and governing equations](https://www.pnas.org/content/pnas/116/45/22445.full.pdf) [![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)`code`](https://github.com/kpchamp/SindyAutoencoders) (SINDY + AE)
      * [Rediscovering orbital mechanics with machine learning](https://arxiv.org/abs/2202.02306)
      * [Back to the Formula -- LHC Edition](https://arxiv.org/abs/2109.10414)
      * [SYMBA: SYMBOLIC COMPUTATION OF SQUARED AMPLITUDES IN HIGH ENERGY PHYSICS WITH MACHINE LEARNING](https://arxiv.org/pdf/2206.08901.pdf) [![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)`code`](https://github.com/ML4SCI/SYMBAHEP)
      
